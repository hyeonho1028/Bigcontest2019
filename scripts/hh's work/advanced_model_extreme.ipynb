{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"advanced_model_extreme.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"wGDLy_XM3epP","colab_type":"code","outputId":"a9782054-683f-427c-fb8a-7b28f182f3a8","executionInfo":{"status":"ok","timestamp":1568018000591,"user_tz":-540,"elapsed":22074,"user":{"displayName":"이현호","photoUrl":"","userId":"01233170983161563057"}},"colab":{"base_uri":"https://localhost:8080/","height":127}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-M_XnxRNQP5C","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sK-XT6Ys6EOG","colab_type":"code","outputId":"8f0dbcca-059d-4c54-a676-c4b8baac78cb","executionInfo":{"status":"ok","timestamp":1568031655290,"user_tz":-540,"elapsed":3038,"user":{"displayName":"이현호","photoUrl":"","userId":"01233170983161563057"}},"colab":{"base_uri":"https://localhost:8080/","height":73}},"source":["import pandas as pd\n","import numpy as np\n","from collections import defaultdict\n","import os\n","import gc\n","import copy\n","\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n","from sklearn.model_selection import KFold\n","from sklearn.model_selection import StratifiedKFold\n","\n","from sklearn.model_selection import train_test_split\n","\n","from sklearn.decomposition import PCA\n","from sklearn.preprocessing import StandardScaler\n","\n","from imblearn.over_sampling import SMOTE\n","from imblearn.under_sampling import RandomUnderSampler\n","\n","from tqdm import tqdm\n","import joblib\n","\n","\n","# model\n","import lightgbm as lgb\n","\n","SEED=42\n","LABEL=None"],"execution_count":1,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n","  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"OFqYB4UI-hGa","colab_type":"text"},"source":["## model"]},{"cell_type":"code","metadata":{"id":"LEnYCT3R1Ees","colab_type":"code","colab":{}},"source":["class model(object):\n","    def __init__(self, train_data, train_label, test1_data, test2_data, folds, seed):\n","        self.train_data = train_data.fillna(0)\n","        self.train_label = train_label\n","        self.test1_data = test1_data.fillna(0)\n","        self.test2_data = test2_data.fillna(0)\n","        self.train_data_st = pd.DataFrame()\n","        self.test1_data_st = pd.DataFrame()\n","        self.test2_data_st = pd.DataFrame()\n","        self.train_data_tas = pd.DataFrame()\n","        self.test1_data_tas = pd.DataFrame()\n","        self.test2_data_tas = pd.DataFrame()\n","        self.features_ = train.drop(columns=['acc_id', 'week']).columns\n","        self.lgb_model_st = defaultdict()\n","        self.lgb_model_tas = defaultdict()\n","        self.rf_model_st = defaultdict()\n","        self.rf_model_tas = defaultdict()\n","        self.true_index = defaultdict()\n","        self.folds = folds\n","        self.seed = seed\n","        self.model = None\n","    \n","    \n","    \n","    def labeling(self):\n","        self.train_data = pd.merge(self.train_data, self.train_label[['acc_id', 'survival_time']], how='left', on='acc_id').dropna().reset_index(drop=True)\n","        for week in range(1, 5):\n","            self.train_data.loc[self.train_data['week']==week, 'survival_time'] = np.minimum(64, self.train_data.loc[self.train_data['week']==week, 'survival_time'] + 7*(4-week))\n","            \n","    def labeling_tas(self, payment):\n","        self.train_data.drop(columns='survival_time', inplace=True)\n","        self.train_data = pd.merge(self.train_data, self.train_label, how='left', on='acc_id').dropna().reset_index(drop=True)\n","        self.train_data['adjust_survival_time'] = self.train_data['survival_time'] + self.train_data['week']*7\n","        \n","        def payment_transform(data):\n","            data['week'] = (data['day']-1)//7 + 1\n","            data = data.groupby(['acc_id', 'week']).sum().reset_index()\n","            return data\n","        payment = payment_transform(payment)\n","        \n","        def temp_func(data):\n","            if data['adjust_survival_time']>64:\n","                over_value = data['adjust_survival_time'] - 64\n","                data['adjust_survival_time'] = data['survival_time'] - over_value\n","            else:\n","                data['adjust_survival_time'] = data['survival_time']\n","            return data['adjust_survival_time']\n","        \n","        self.train_data['adjust_survival_time'] = self.train_data[['survival_time', 'adjust_survival_time']].apply(temp_func, axis=1)\n","        self.train_data['payment'] = 0\n","        \n","        for week in range(1, 4):\n","            self.train_data.loc[self.train_data['week']==week, 'payment'] = pd.merge(self.train_data.loc[self.train_data['week']==week, 'acc_id'], \n","                                                                                     payment[payment['week']>week].groupby(\n","                                                                                         ['acc_id'])['amount_spent'].sum().reset_index().rename(columns={'amount_spent':'payment'}), \n","                                                                                     how='left', on='acc_id')['payment']\n","            self.train_data = self.train_data.fillna(0)\n","        else:\n","            self.train_data['total_amount_spent'] = self.train_data['amount_spent'] * self.train_data['adjust_survival_time'] + self.train_data['payment']\n","            self.train_data = self.train_data.drop(columns=['amount_spent', 'payment'])\n","            for week in range(1, 5):\n","                self.train_data.loc[self.train_data['week']==week, 'survival_time'] = np.minimum(64, self.train_data.loc[self.train_data['week']==week, 'survival_time'] + 7*(4-week))\n","            else:\n","                self.train_data = self.train_data.drop(columns=['adjust_survival_time', 'survival_time'])\n","                \n","    \n","    \n","    def train_fs(self, params, iteration):\n","        self.model=model\n","        LABEL='survival_time'\n","        for idx, true in enumerate(np.unique(self.train_data[LABEL].apply(lambda x: x if x==1 or x==64 else x//7*7).apply(lambda x: 1 if x==0 else x))):\n","            self.true_index[true] = idx\n","        else:\n","            self.train_data[LABEL] = self.train_data[LABEL].apply(lambda x: x if x==1 or x==64 else x//7*7).apply(lambda x: 1 if x==0 else x).apply(lambda x: self.true_index[x])\n","            \n","        skf = StratifiedKFold(n_splits=self.folds, random_state=self.seed, shuffle=True)\n","        rus = RandomUnderSampler(random_state=self.seed)\n","        for idx, (trn_idx, val_idx) in enumerate(skf.split(self.train_data, self.train_data[LABEL])):\n","\n","            temp_train_data = pd.DataFrame()\n","            X, y = rus.fit_resample(self.train_data.drop(columns='survival_time'), self.train_data['survival_time'])\n","            temp_train_data = pd.DataFrame(np.concatenate([X, y.reshape(-1, 1)], 1))\n","            temp_train_data.columns = self.train_data.columns\n","            \n","            trn_label = temp_train_data[LABEL]\n","            val_label = self.train_data.loc[val_idx, LABEL]\n","            train_df = lgb.Dataset(temp_train_data[self.features_], label=trn_label)\n","            valid_df = lgb.Dataset(self.train_data.loc[val_idx, self.features_], label=val_label)\n","\n","            lgb_model = lgb.train(params, train_df, iteration, valid_sets = [train_df, valid_df], early_stopping_rounds=150, verbose_eval=1000)\n","            self.lgb_model_st['model'+str(idx)] = lgb_model\n","            break\n","\n","    def train_st(self, params, iteration, model):\n","        self.model=model\n","        LABEL='survival_time'\n","        for idx, true in enumerate(np.unique(self.train_data_st[LABEL].apply(lambda x: x if x==1 or x==64 else x//7*7).apply(lambda x: 1 if x==0 else x))):\n","            self.true_index[true] = idx\n","        else:\n","            self.train_data_st[LABEL] = self.train_data_st[LABEL].apply(lambda x: x if x==1 or x==64 else x//7*7).apply(lambda x: 1 if x==0 else x).apply(lambda x: self.true_index[x])\n","            \n","        skf = StratifiedKFold(n_splits=self.folds, random_state=self.seed, shuffle=True)\n","        rus = RandomUnderSampler(random_state=self.seed)\n","        for idx, (trn_idx, val_idx) in enumerate(skf.split(self.train_data_st, self.train_data_st[LABEL])):\n","\n","            temp_train_data = pd.DataFrame()\n","            X, y = rus.fit_resample(self.train_data_st.drop(columns='survival_time'), self.train_data_st['survival_time'])\n","            temp_train_data = pd.DataFrame(np.concatenate([X, y.reshape(-1, 1)], 1))\n","            temp_train_data.columns = self.train_data_st.columns\n","            \n","            trn_label = temp_train_data[LABEL]\n","            val_label = self.train_data_st.loc[val_idx, LABEL]\n","            print(temp_train_data.columns)\n","            print(self.features_)\n","            if self.model=='lgb':\n","                train_df = lgb.Dataset(temp_train_data[self.features_], label=trn_label)\n","                valid_df = lgb.Dataset(self.train_data_st.loc[val_idx, self.features_], label=val_label)\n","\n","                lgb_model = lgb.train(params, train_df, iteration, valid_sets = [train_df, valid_df], early_stopping_rounds=150, verbose_eval=1000)\n","                self.lgb_model_st['model'+str(idx)] = lgb_model\n","                joblib.dump(lgb_model, \"/content/drive/My Drive/bigcontest2019/scripts/hh's work/model_joblib/lgb_st_\" + str(self.seed) + '_' + str(idx) + '.ckpt')\n","                \n","            elif self.model=='rf':\n","                rf_model = RandomForestClassifier(n_estimators=1000, random_state=self.seed, max_depth=8).fit(temp_train_data[self.features_], trn_label)\n","                self.rf_model_st['model'+str(idx)] = rf_model\n","                joblib.dump(rf_model, \"/content/drive/My Drive/bigcontest2019/scripts/hh's work/model_joblib/rf_st_\" + str(self.seed) + '_' + str(idx) + '.ckpt')\n","    \n","    \n","    \n","    \n","    \n","    \n","    \n","    \n","    \n","    def train_tas(self, params, iteration, model, model_extraction):\n","        np.random.seed(self.seed)\n","        LABEL='total_amount_spent'\n","        kf = KFold(n_splits=self.folds, random_state=self.seed, shuffle=True)\n","        \n","        for idx, (trn_idx, val_idx) in enumerate(kf.split(self.train_data)):\n","            \n","            temp_train_data = pd.DataFrame()\n","            round_basis=1;SIZE=46\n","            for round_value in np.round(self.train_data['total_amount_spent'], round_basis).value_counts().index:\n","                temp_df = self.train_data.loc[trn_idx][np.round(self.train_data.loc[trn_idx, 'total_amount_spent'], round_basis).isin([round_value])]\n","                try:\n","                    temp_df = temp_df.loc[np.random.choice(temp_df.index, size=SIZE, replace=False)]\n","                except:\n","                    pass\n","                temp_train_data = pd.concat([temp_train_data, temp_df]).reset_index(drop=True)\n","            else:\n","                temp_train_data = temp_train_data[temp_train_data['total_amount_spent']<40].reset_index(drop=True)\n","                \n","                trn_label = temp_train_data[LABEL]\n","                val_label = self.train_data.loc[val_idx, LABEL]\n","                if self.model =='lgb':\n","                    train_df = lgb.Dataset(temp_train_data[self.features_], label=trn_label)\n","                    valid_df = lgb.Dataset(self.train_data.loc[val_idx, self.features_], label=val_label)\n","\n","                    lgb_model = lgb.train(params, train_df, iteration, valid_sets = [train_df, valid_df], early_stopping_rounds=1000, verbose_eval=3000)\n","                    self.lgb_model_tas['model'+str(idx)] = lgb_model\n","                    if model_extraction:\n","                        break\n","                    else:\n","                        joblib.dump(lgb_model, \"/content/drive/My Drive/bigcontest2019/scripts/hh's work/model_joblib/lgb_tas_\" + str(self.seed) + '_' + str(idx) + '.ckpt')\n","                elif self.model =='rf':\n","                    rf_model = RandomForestRegressor(n_estimators=200, random_state=self.seed, max_depth=8).fit(temp_train_data[self.features_], trn_label)\n","                    self.rf_model_tas['model'+str(idx)] = rf_model\n","                    joblib.dump(rf_model, \"/content/drive/My Drive/bigcontest2019/scripts/hh's work/model_joblib/rf_tas_\" + str(self.seed) + '_' + str(idx) + '.ckpt')\n","                \n","\n","                \n","                \n","    \n","    def infer_oof(self, model):\n","        self.model=model\n","        LABEL='survival_time'\n","        oof = np.zeros(len(self.train_data))\n","        skf = StratifiedKFold(n_splits=self.folds, random_state=self.seed, shuffle=True)\n","\n","        for idx, (_, val_idx) in enumerate(skf.split(self.train_data_st, self.train_data_st[LABEL])):\n","            if self.model=='lgb':\n","                oof[val_idx] = np.argmax(self.lgb_model_st['model'+str(idx)].predict(self.train_data_st.loc[val_idx, self.features_]), axis=1)\n","            elif self.model=='rf':\n","                oof[val_idx] = self.rf_model_st['model'+str(idx)].predict(self.train_data_st.loc[val_idx, self.features_])\n","        else:\n","            oof = pd.concat([self.train_data_st, pd.DataFrame(oof, columns=['infer_survival_time'])], 1)\n","            oof = oof.loc[oof['week']==4, ['acc_id', 'survival_time', 'infer_survival_time']].reset_index(drop=True)\n","            self.oof = oof.copy()\n","            \n","            temp_dict = defaultdict()\n","            for true, idx in zip(self.true_index.keys(), self.true_index.values()):\n","                temp_dict[idx] = true\n","            else:    \n","                self.oof['survival_time'] = self.oof['survival_time'].apply(lambda x: temp_dict[x])\n","                self.oof['infer_survival_time'] = self.oof['infer_survival_time'].apply(lambda x: temp_dict[x])\n","                return self.oof\n","    def infer_tas_oof(self, model):\n","        LABEL='total_amount_spent'\n","        oof = np.zeros(len(self.train_data))\n","        kf = KFold(n_splits=self.folds, random_state=self.seed, shuffle=True)\n","        \n","        for idx, (_, val_idx) in enumerate(kf.split(self.train_data)):\n","            valid_df = self.train_data.loc[val_idx]\n","            if self.model=='lgb':\n","                oof[val_idx] = self.lgb_model_tas['model'+str(idx)].predict(valid_df[self.features_])\n","            elif self.model=='rf':\n","                oof[val_idx] = self.rf_model_tas['model'+str(idx)].predict(valid_df[self.features_])\n","        else:\n","            oof = pd.concat([self.train_data, pd.DataFrame(oof, columns=['infer_total_amount_spent'])], 1)\n","            oof = oof.loc[oof['week']==4, ['acc_id', 'total_amount_spent', 'infer_total_amount_spent']].reset_index(drop=True)\n","            self.oof_tas = oof\n","            return self.oof_tas\n","                \n","    \n","    \n","    \n","    \n","    \n","    \n","    \n","#     def infer_pred(self):\n","#         test1 = self.test1_data.loc[self.test1_data['week']==4].reset_index(drop=True)\n","#         test2 = self.test2_data.loc[self.test2_data['week']==4].reset_index(drop=True)\n","#         pred1 = np.zeros([len(test1), self.folds])\n","#         pred2 = np.zeros([len(test2), self.folds])\n","        \n","#         for idx in range(self.folds):\n","#             if self.model=='lgb':\n","#                 pred1[:, idx] = np.argmax(self.lgb_model_st['model'+str(idx)].predict(test1[self.features_]), axis=1)\n","#                 pred2[:, idx] = np.argmax(self.lgb_model_st['model'+str(idx)].predict(test2[self.features_]), axis=1)\n","#             elif self.model=='rf':\n","#                 pred1[:, idx] = self.rf_model_st['model'+str(idx)].predict(test1[self.features_])\n","#                 pred2[:, idx] = self.rf_model_st['model'+str(idx)].predict(test2[self.features_])\n","#         else:\n","#             test1 = pd.concat([test1['acc_id'], pd.DataFrame(pred1)], 1)\n","#             test2 = pd.concat([test2['acc_id'], pd.DataFrame(pred2)], 1)\n","            \n","#             temp_dict = defaultdict()\n","#             for true, idx in zip(self.true_index.keys(), self.true_index.values()):\n","#                 temp_dict[idx] = true\n","#             else:\n","#                 for i in range(5):\n","#                     test1[i] = test1[i].apply(lambda x: temp_dict[x])\n","#                     test2[i] = test2[i].apply(lambda x: temp_dict[x])\n","#                 else:\n","#                     self.pred_test1 = test1\n","#                     self.pred_test2 = test2    \n","#                     return self.pred_test1, self.pred_test2\n","    \n","#     def infer_tas_pred(self):\n","#         test1 = self.test1_data.loc[self.test1_data['week']==4].reset_index(drop=True)\n","#         test2 = self.test2_data.loc[self.test2_data['week']==4].reset_index(drop=True)\n","#         pred1 = np.zeros([len(test1), self.folds])\n","#         pred2 = np.zeros([len(test2), self.folds])\n","        \n","#         for idx in range(self.folds):\n","#             if self.model=='lgb':\n","#                 pred1[:, idx] = self.lgb_model_tas['model'+str(idx)].predict(test1[self.features_])\n","#                 pred2[:, idx] = self.lgb_model_tas['model'+str(idx)].predict(test2[self.features_])\n","#             elif self.model=='rf':\n","#                 pred1[:, idx] = self.rf_model_tas['model'+str(idx)].predict(test1[self.features_])\n","#                 pred2[:, idx] = self.rf_model_tas['model'+str(idx)].predict(test2[self.features_])\n","#             pred1[:, idx][pred1[:, idx]<0] = 0\n","#             pred2[:, idx][pred2[:, idx]<0] = 0\n","#         else:\n","#             test1 = pd.concat([test1['acc_id'], pd.DataFrame(pred1)], 1)\n","#             test2 = pd.concat([test2['acc_id'], pd.DataFrame(pred2)], 1)\n","#             return test1, test2\n","        \n","\n","        \n","        \n","        \n","        \n","    def load(self, return_data):\n","        if return_data=='train':\n","            return self.train_data\n","        elif return_data=='test1':\n","            return self.test1_data\n","        elif return_data=='test2':\n","            return self.test2_data\n","        elif return_data=='model_st':\n","            return self.lgb_model_st\n","        elif return_data=='model_tas':\n","            return self.lgb_model_tas\n","        elif return_data=='true_dict':\n","            return self.true_index\n","        elif return_data=='feature':\n","            return self.features_\n","        \n"," \n","    def joblib_load_oof(self, model):\n","        self.model=model\n","        LABEL='survival_time'\n","        \n","        for idx, true in enumerate(np.unique(self.train_data[LABEL].apply(lambda x: x if x==1 or x==64 else x//7*7).apply(lambda x: 1 if x==0 else x))):\n","            self.true_index[true] = idx\n","        else:\n","            self.train_data[LABEL] = self.train_data[LABEL].apply(lambda x: x if x==1 or x==64 else x//7*7).apply(lambda x: 1 if x==0 else x).apply(lambda x: self.true_index[x])\n","            \n","        oof = np.zeros(len(self.train_data))\n","        skf = StratifiedKFold(n_splits=self.folds, random_state=self.seed, shuffle=True)\n","\n","        for idx, (_, val_idx) in enumerate(skf.split(self.train_data, self.train_data[LABEL])):\n","            if self.model=='lgb':\n","                lgb_model = joblib.load(\"/content/drive/My Drive/bigcontest2019/scripts/hh's work/model_joblib/lgb_st_\" + str(self.seed) + \"_\" + str(idx) + \".ckpt\")\n","                oof[val_idx] = np.argmax(lgb_model.predict(self.train_data.loc[val_idx, self.features_]), axis=1)\n","            elif self.model=='rf':\n","                rf_model = joblib.load(\"/content/drive/My Drive/bigcontest2019/scripts/hh's work/model_joblib/rf_st_\" + str(self.seed) + \"_\" + str(idx) + \".ckpt\")\n","                oof[val_idx] = rf_model.predict(self.train_data.loc[val_idx, self.features_])\n","        else:\n","            oof = pd.concat([self.train_data, pd.DataFrame(oof, columns=['infer_survival_time'])], 1)\n","            oof = oof.loc[oof['week']==4, ['acc_id', 'survival_time', 'infer_survival_time']].reset_index(drop=True)\n","            self.oof = oof.copy()\n","            \n","            temp_dict = defaultdict()\n","            for true, idx in zip(self.true_index.keys(), self.true_index.values()):\n","                temp_dict[idx] = true\n","            else:    \n","                self.oof['survival_time'] = self.oof['survival_time'].apply(lambda x: temp_dict[x])\n","                self.oof['infer_survival_time'] = self.oof['infer_survival_time'].apply(lambda x: temp_dict[x])\n","                return self.oof\n","            \n","    def joblib_load_tas_oof(self, model):\n","        LABEL='total_amount_spent'\n","        oof = np.zeros(len(self.train_data))\n","        kf = KFold(n_splits=self.folds, random_state=self.seed, shuffle=True)\n","        \n","        for idx, (_, val_idx) in enumerate(kf.split(self.train_data)):\n","            valid_df = self.train_data.loc[val_idx]\n","            if self.model=='lgb':\n","                lgb_model = joblib.load(\"/content/drive/My Drive/bigcontest2019/scripts/hh's work/model_joblib/lgb_tas_\" + str(self.seed) + \"_\" + str(idx) + \".ckpt\")\n","                oof[val_idx] = lgb_model.predict(valid_df[self.features_])\n","            elif self.model=='rf':\n","                rf_model = joblib.load(\"/content/drive/My Drive/bigcontest2019/scripts/hh's work/model_joblib/rf_tas_\" + str(self.seed) + \"_\" + str(idx) + \".ckpt\")\n","                oof[val_idx] = rf_model.predict(valid_df[self.features_])\n","        else:\n","            oof = pd.concat([self.train_data, pd.DataFrame(oof, columns=['infer_total_amount_spent'])], 1)\n","            oof = oof.loc[oof['week']==4, ['acc_id', 'total_amount_spent', 'infer_total_amount_spent']].reset_index(drop=True)\n","            self.oof_tas = oof\n","            return self.oof_tas\n","        \n","        \n","    def add_transform(self, method):\n","        train = self.train_data.copy()\n","        test1 = self.test1_data.copy()\n","        test2 = self.test2_data.copy()\n","        \n","        if method=='survival_time':\n","            feature_imp = pd.read_csv('feature_importance_st.csv')\n","            feature_imp = feature_imp.iloc[-500:, :]['Feature'].tolist()\n","            self.features_ = feature_imp.copy()\n","            feature_imp.extend(['acc_id', 'week'])\n","            \n","            self.test1_data_st = self.test1_data[feature_imp]\n","            self.test2_data_st = self.test2_data[feature_imp]\n","            \n","            feature_imp.extend(['survival_time'])\n","            self.train_data_st = self.train_data[feature_imp]\n","            \n","        elif method=='total_amount_spent':\n","            feature_imp = pd.read_csv('feature_importance_tas.csv')\n","            feature_imp = feature_imp.iloc[-500:, :]['Feature'].tolist()\n","            self.features_ = feature_imp.copy()\n","            feature_imp.extend(['acc_id', 'week'])\n","            \n","            self.test1_data_tas = self.test1_data[feature_imp]\n","            self.test2_data_tas = self.test2_data[feature_imp]\n","            \n","            feature_imp.extend(['total_amount_spent'])\n","            self.train_data_tas = self.train_data[feature_imp]\n","            \n","        else:\n","            train = self.train_data.copy()\n","            test1 = self.test1_data.copy()\n","            test2 = self.test2_data.copy()\n","        \n","            all_data = pd.concat([train, test1, test2])\n","            \n","            # play style\n","            sum_columns = all_data.columns[[column[-3:]=='sum' for column in all_data.columns]]\n","            playtimesum = all_data['act_playtimesum']\n","            for column in sum_columns:\n","                if column!='act_playtimesum':\n","                    all_data['derive' + str(column)] = all_data[column]/playtimesum\n","\n","            # PCA\n","            pca_columns = all_data.drop(columns=['acc_id', 'week']).columns\n","            temp_df = pd.DataFrame(np.unique(all_data['acc_id']), columns=['acc_id'])\n","            for column in pca_columns:\n","                try:\n","                    temp_pca = pd.pivot_table(all_data, index='acc_id', columns='week', values=column).fillna(0)\n","                    pca_component = PCA(n_components=1, random_state=42).fit_transform(StandardScaler().fit_transform(temp_pca))\n","                    temp_df = pd.concat([temp_df, pd.DataFrame(pca_component, columns=['pca_'+str(column)])], 1)\n","                except:\n","                    pass\n","            else:\n","                all_data = pd.merge(all_data, temp_df, how='left', on='acc_id')\n","\n","\n","            # week\n","            dummy_df = pd.get_dummies(all_data.groupby('acc_id')['week'].first()).reset_index()\n","            dummy_df.columns = ['acc_id', 'enter_week1', 'enter_week2', 'enter_week3', 'enter_week4']\n","            all_data = pd.merge(all_data, dummy_df, how='left', on='acc_id')\n","        \n","            train = all_data.iloc[:train.shape[0], :]\n","            test1 = all_data.iloc[train.shape[0]:train.shape[0]+test1.shape[0], :].reset_index(drop=True)\n","            test2 = all_data.iloc[-test2.shape[0]:, :].reset_index(drop=True)\n","        \n","            self.train_data = train\n","            self.test1_data = test1\n","            self.test2_data = test2\n","            \n","            self.features_ = self.train_data.drop(columns=['acc_id','week']).columns\n","            \n","            \n","PARAMS_ST = {\n","    'objective':'multiclass',\n","    'num_class':11,\n","    \"boosting\": \"gbdt\",\n","    'learning_rate': 0.02,\n","    'subsample' : 0.6,\n","    'sumsample_freq':1,\n","    'colsample_bytree':0.221856,\n","    'max_depth': 8,\n","    'max_bin':255,\n","    \"lambda_l1\": 0.25,\n","    \"lambda_l2\": 1,\n","    'min_child_weight': 0.2,\n","    'min_child_samples': 20,\n","    'min_gain_to_split':0.02,\n","    'min_data_in_bin':3,\n","    'bin_construct_sample_cnt':5000,\n","    'cat_l2':10,\n","    'verbose':-1,\n","    'nthread':-1,\n","    'seed':SEED\n","}\n","\n","PARAMS_TAS = {\n","    'objective':'regression',\n","    \"boosting\": \"gbdt\",\n","    'learning_rate': 0.02,\n","    'subsample' : 0.6,\n","    'sumsample_freq':1,\n","    'colsample_bytree':0.221856,\n","    'max_depth': 8,\n","    'max_bin':255,\n","    \"lambda_l1\": 0.25,\n","    \"lambda_l2\": 1,\n","    'min_child_weight': 0.2,\n","    'min_child_samples': 20,\n","    'min_gain_to_split':0.02,\n","    'min_data_in_bin':3,\n","    'bin_construct_sample_cnt':5000,\n","    'cat_l2':10,\n","    'verbose':-1,\n","    'nthread':-1,\n","    'metrics':'rmse',\n","    'seed':SEED\n","}\n","try:\n","    os.chdir('drive/My Drive/bigcontest2019/fbip team/preprocess')\n","except:\n","    pass"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ij0L4-T_OGKL","colab_type":"text"},"source":["## main"]},{"cell_type":"code","metadata":{"id":"UAD7VQTaNE1O","colab_type":"code","colab":{}},"source":["train = pd.read_csv('train.csv')\n","test1 = pd.read_csv('test1.csv')\n","test2 = pd.read_csv('test2.csv')\n","\n","train_label = pd.read_csv('../raw/train_label.csv')\n","train_payment = pd.read_csv('../raw/train_payment.csv')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FNxPLPq71KNs","colab_type":"code","colab":{}},"source":["FOLDS=5\n","SEED=42\n","select_model='lgb'\n","\n","main_model = model(train, train_label, test1, test2, FOLDS, SEED)\n","print('start main_model')\n","main_model.add_transform(method='None')\n","\n","# survivatl time\n","main_model.labeling()\n","main_model.train_fs(PARAMS_ST, 5000)\n","\n","feature_imp = pd.DataFrame(sorted(zip(main_model.load('model_st')['model0'].feature_importance(), main_model.load('feature'))), columns=['Value','Feature'])\n","feature_imp.to_csv('feature_importance_st.csv', index=False)\n","\n","main_model.add_transform(method='survival_time')\n","main_model.train_st(PARAMS_ST, 5000, select_model)\n","oof_st = main_model.infer_oof(select_model)\n","\n","# model_extraction=True\n","# # total amount_spent\n","# main_model.labeling_tas(train_payment)\n","# main_model.train_tas(PARAMS_TAS, 50000, select_model, model_extraction)\n","\n","# feature_imp = pd.DataFrame(sorted(zip(main_model.load('model_tas')['model0'].feature_importance(), main_model.load('feature'))), columns=['Value','Feature'])\n","# feature_imp.to_csv('feature_importance_tas.csv', index=False)\n","\n","# model_extraction=False\n","# main_model.add_transform(method='total_amount_spent')\n","# main_model.labeling_tas()\n","# main_model.train_tas(PARAMS_TAS, 50000, select_model, model_extraction)\n","# oof_tas = main_model.infer_tas_oof(select_model)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DYSF7Q1hxL7-","colab_type":"code","colab":{}},"source":["oof_st"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HNUvcG-MniBQ","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7nIqItZ2OSLU","colab_type":"code","colab":{}},"source":["TYPE='activity'\n","FOLDS=5\n","SEED=42\n","select_model='lgb'\n","\n","main_model = model(train, train_label, test1, test2, TYPE, FOLDS, SEED)\n","print('start main_model')\n","main_model.add_transform()\n","main_model.labeling()\n","main_model.train_st(PARAMS_ST, 5000, select_model)\n","oof_st = main_model.infer_oof(select_model)\n","\n","main_model.labeling_tas(train_payment)\n","main_model.train_tas(PARAMS_TAS, 50000, select_model)\n","oof_tas = main_model.infer_tas_oof(select_model)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bHrkWg8JQojR","colab_type":"code","colab":{}},"source":["main_model.labeling_tas(train_payment)\n","main_model.train_tas(PARAMS_TAS, 50000, select_model)\n","oof_tas = main_model.infer_tas_oof(select_model)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PpP4kqePdLg6","colab_type":"code","outputId":"19622368-6f68-4599-e1e6-b6252a6507bd","executionInfo":{"status":"ok","timestamp":1567939473462,"user_tz":-540,"elapsed":742,"user":{"displayName":"이현호","photoUrl":"","userId":"01233170983161563057"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["feature_imp = pd.DataFrame(sorted(zip(main_model.load('model_tas')['model0'].feature_importance(), main_model.load('feature'))), columns=['Value','Feature'])\n","joblib.dump(feature_imp, \"/content/drive/My Drive/bigcontest2019/scripts/hh's work/feature_importance/feature_importance_tas.ckpt\")\n","\n","feature_imp = pd.DataFrame(sorted(zip(main_model.load('model_st')['model0'].feature_importance(), main_model.load('feature'))), columns=['Value','Feature'])\n","joblib.dump(feature_imp, \"/content/drive/My Drive/bigcontest2019/scripts/hh's work/feature_importance/feature_importance_st.ckpt\")"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[\"/content/drive/My Drive/bigcontest2019/scripts/hh's work/feature_importance/feature_importance_st.ckpt\"]"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"U6A9zt-kebLz","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TA9pQtwDaO7Q","colab_type":"code","outputId":"5fb2a7bd-03ac-485d-d053-d2846d35576d","executionInfo":{"status":"ok","timestamp":1567939125169,"user_tz":-540,"elapsed":634,"user":{"displayName":"이현호","photoUrl":"","userId":"01233170983161563057"}},"colab":{"base_uri":"https://localhost:8080/","height":53}},"source":["score_function(oof_transform(oof_st, oof_tas), true_train_label)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["34942.091611892596\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["34942.091611892596"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"f929I_7GfWUu","colab_type":"code","outputId":"1cd250af-1641-411d-8342-1c4ce26f9e2b","executionInfo":{"status":"ok","timestamp":1567877291775,"user_tz":-540,"elapsed":514,"user":{"displayName":"이현호","photoUrl":"","userId":"01233170983161563057"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["feature_imp = pd.DataFrame(sorted(zip(main_model.load('model_tas')['model0'].feature_importance(), main_model.load('feature'))), columns=['Value','Feature'])\n","joblib.dump(feature_imp, \"/content/drive/My Drive/bigcontest2019/scripts/hh's work/feature_importance/feature_importance2.ckpt\")"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[\"/content/drive/My Drive/bigcontest2019/scripts/hh's work/feature_importance/feature_importance2.ckpt\"]"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"MxqiJ0NDxOs9","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kiLOrnejjfHC","colab_type":"code","outputId":"8a03d4f8-23a6-4d15-f64e-e0eb9dd75bba","executionInfo":{"status":"ok","timestamp":1567849432116,"user_tz":-540,"elapsed":225151,"user":{"displayName":"이현호","photoUrl":"","userId":"01233170983161563057"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["fis = joblib.load(\"/content/drive/My Drive/bigcontest2019/scripts/hh's work/feature_importance/feature_importance.ckpt\")\n","fis = fis.loc[fis['Value']>25, 'Feature'].tolist()\n","fis.extend(['acc_id', 'week'])\n","\n","def feature_selection(data, fis):\n","    df = data.copy()\n","    \n","    sum_columns = df.columns[[column[-3:]=='sum' for column in df.columns]]\n","    df = df[df.columns[(pd.Series(df.columns).isin(fis)) | (pd.Series(df.columns).isin(sum_columns))]]\n","    \n","    playtimesum = df['playtimesum']\n","    for column in sum_columns[1:]:\n","        df['derive' + str(column)] = df[column]/playtimesum\n","    else:\n","        df = df[fis]\n","        return df\n","\n","TYPE='activity'\n","FOLDS=5\n","SEED=42\n","select_model='rf'\n","\n","main_model = model(feature_selection(train, fis), train_label, feature_selection(test1, fis), feature_selection(test2, fis), TYPE, FOLDS, SEED)\n","print('start main_model')\n","main_model.labeling()\n","oof_st_rf = main_model.joblib_load_oof(select_model)\n","\n","main_model.labeling_tas(train_payment)\n","oof_tas_rf = main_model.joblib_load_tas_oof(select_model)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["start main_model\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bjh24HkK8C8L","colab_type":"code","colab":{}},"source":["# feature_imp = pd.DataFrame(sorted(zip(main_model.load('model_tas')['model0'].feature_importance(), main_model.load('feature'))), columns=['Value','Feature'])\n","# joblib.dump(feature_imp, \"/content/drive/My Drive/bigcontest2019/scripts/hh's work/feature_importance/feature_importance.ckpt\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lR1akul8OSOm","colab_type":"code","outputId":"d6b0f752-ae5c-4659-fc85-839625f6e4a0","executionInfo":{"status":"ok","timestamp":1567850158769,"user_tz":-540,"elapsed":528,"user":{"displayName":"이현호","photoUrl":"","userId":"01233170983161563057"}},"colab":{"base_uri":"https://localhost:8080/","height":53}},"source":["oof_tas_ensembles = oof_tas_rf.copy()\n","oof_tas_ensembles['infer_total_amount_spent'] = oof_tas_rf['infer_total_amount_spent']*0.05 + oof_tas_lgb['infer_total_amount_spent']*0.95\n","\n","# 예측, 실제\n","score_function(oof_transform(oof_st_lgb, oof_tas_ensembles), true_train_label)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["35190.25717482952\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["35190.25717482952"]},"metadata":{"tags":[]},"execution_count":57}]},{"cell_type":"code","metadata":{"id":"hSxx9wxSIR1j","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IxKLIhr9F-m_","colab_type":"code","colab":{}},"source":["main_pred_st1, main_pred_st2 = main_model.infer_pred()\n","main_pred_tas1, main_pred_tas2 = main_model.infer_tas_pred()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Uu4VKZjVF-ui","colab_type":"code","colab":{}},"source":["pred_transform(main_pred_st1, main_pred_tas1, test1_activity['acc_id'].unique()).to_csv('/content/test1_predict.csv', index=False)\n","pred_transform(main_pred_st2, main_pred_tas2, test2_activity['acc_id'].unique()).to_csv('/content/test2_predict.csv', index=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GiQpIpEsF-q7","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"U3FEFmy8nA6v","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hfT0leHp1vSE","colab_type":"code","colab":{}},"source":["# act_pred_st1, act_pred_st2 = activity_model.infer_pred()\n","# act_pred_tas1, act_pred_tas2 = activity_model.infer_tas_pred()\n","\n","# pay_pred_st1, pay_pred_st2 = payment_model.infer_pred()\n","# pay_pred_tas1, pay_pred_tas2 = payment_model.infer_tas_pred()\n","\n","# tra_pred_st1, tra_pred_st2 = trade_model.infer_pred()\n","# tra_pred_tas1, tra_pred_tas2 = trade_model.infer_tas_pred()\n","\n","# com_pred_st1, com_pred_st2 = combat_model.infer_pred()\n","# com_pred_tas1, com_pred_tas2 = combat_model.infer_tas_pred()\n","\n","# ple_pred_st1, ple_pred_st2 = pledge_model.infer_pred()\n","# ple_pred_tas1, ple_pred_tas2 = pledge_model.infer_tas_pred()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6erAxyzNH-CR","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bF2VfPzhH-IY","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tgChsHqkH-GA","colab_type":"code","colab":{}},"source":["oop_st = pd.concat([act_oof_st, pay_oof_st, tra_oof_st, com_oof_st, ple_oof_st]).groupby('acc_id').median().reset_index()\n","# oop_st = pd.concat([act_oof_st, pay_oof_st, tra_oof_st, com_oof_st, ple_oof_st]).groupby('acc_id').agg(lambda x: x.value_counts().index[0]).reset_index()\n","oop_tas = pd.concat([act_oof_tas, pay_oof_tas, tra_oof_tas, com_oof_tas, ple_oof_tas]).groupby('acc_id').median().reset_index()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Drmj8HCn1Cnl","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fjaHUQYFYQ0O","colab_type":"code","colab":{}},"source":["# metrics\n","from scripts.metrics.score_function import score_function\n","\n","def oof_transform(st, tas):\n","    st_t = st.copy()\n","    tas_t = tas.copy()\n","\n","    tas_t.loc[tas['infer_total_amount_spent']<0, 'infer_total_amount_spent'] = 0\n","    \n","    oof_df = pd.merge(st_t, tas_t, how='left', on='acc_id')[['acc_id', 'infer_survival_time', 'infer_total_amount_spent']]\n","    oof_df.columns = ['acc_id', 'survival_time', 'amount_spent']\n","    oof_df['amount_spent'] = oof_df['amount_spent']/oof_df['survival_time']\n","    return oof_df\n","\n","def pred_transform(st, tas, acc_id):\n","    st_t = st.copy()\n","    tas_t = tas.copy()\n","    \n","    st_t['survival_time'] = st_t.drop(columns='acc_id').median(1)\n","    tas_t['amount_spent'] = tas_t.drop(columns='acc_id').median(1)\n","    \n","    pred_df = pd.merge(st_t, tas_t, how='left', on='acc_id')[['acc_id', 'survival_time', 'amount_spent']]\n","    pred_df['amount_spent'] = pred_df['amount_spent']/pred_df['survival_time']\n","    \n","    pred_df = pred_df[pred_df['acc_id'].isin(acc_id)]\n","    return pred_df\n","\n","# 예측, 실제\n","score_function(oof_transform(act_oof_st, act_oof_tas),\n","               true_train_label)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"w8S3u2N2-kMH","colab_type":"text"},"source":["# submission"]},{"cell_type":"code","metadata":{"id":"DBr7HXHg89M9","colab_type":"code","colab":{}},"source":["pred1_st = pd.concat([act_pred_st1, pay_pred_st1, tra_pred_st1, com_pred_st1, ple_pred_st1]).groupby('acc_id').median().reset_index()\n","pred1_tas = pd.concat([act_pred_tas1, pay_pred_tas1, tra_pred_tas1, com_pred_tas1, ple_pred_tas1]).groupby('acc_id').median().reset_index()\n","\n","pred2_st = pd.concat([act_pred_st2, pay_pred_st2, tra_pred_st2, com_pred_st2, ple_pred_st2]).groupby('acc_id').median().reset_index()\n","pred2_tas = pd.concat([act_pred_tas2, pay_pred_tas2, tra_pred_tas2, com_pred_tas2, ple_pred_tas2]).groupby('acc_id').median().reset_index()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RxkCaXrN-kI1","colab_type":"code","colab":{}},"source":["pred_transform(pred1_st, pred1_tas, test1_activity['acc_id'].unique()).to_csv('/content/test1_predict.csv', index=False)\n","pred_transform(pred2_st, pred2_tas, test2_activity['acc_id'].unique()).to_csv('/content/test2_predict.csv', index=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VAXA9yRoCNwE","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UR6h_5DB9-qZ","colab_type":"code","colab":{}},"source":["pred_transform(act_pred_st1, act_pred_tas1, test1_activity['acc_id'].unique()).to_csv('/content/test1_predict.csv', index=False)\n","pred_transform(act_pred_st2, act_pred_tas2, test2_activity['acc_id'].unique()).to_csv('/content/test2_predict.csv', index=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"baZjm6CPEbsF","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9NLr0Stb0Iat","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nn8uID15MCxV","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}